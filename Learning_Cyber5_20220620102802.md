# Attaques et defenses en intelligence artificielle
## Introduction a l'intelligence artificielle 
Definitions
- Machine Learning : Automatisation d'un ensemble de taches (routine ou trop complexe)
Se base sur l'extraction de connaissance et developpement de modele a partir de donnees
- Deep Learning. Sous categorie d'algorithme d'apprentissage. Se base sur des reseaux de neurones
- intelligence artificielle : Cree dans les annees 50. Cherche a reproduire les capacites humaines
Surtout base sur les aspects numeriques de nos jours. Vise a faire executer par l'ordinateur de taches pour lesquelles l'homme est plus performant
- Histoire de l'IA : Travaux de Turing pour generer de la connaissance a partir de connaissances de base. Jusque dans les annees 70; beaucoup d'echecs; quelques resultats sont demontres (impossible de representer l'ensemble des connaissances; laisser une partie du systeme non decrite)
  - De 70-80 : Specialisation des IA (Comprehension du language naturel; demonstration de theoreme; representation des connaissances; jeux(echecs; dames...))
  - 80-2005 : Hiver de l'IA (tentative de reconnaissance d'images)
  - 2005-now : Grace aux donnees et la puissance de calcul; provoque l'essor de l'IA avec le ML et l'avenement du Deep Learning (DL)
Application :
- Vision par ordinateur : extraction d'information a partir d'une image
- Traitement du language naturel : traduction; resume; comprendre le sentiment d'un texte; synthese vocal
- Traitement des donnees audios : decryptage de donnees sonores
- Developpement de modeles predictifs 
- Systeme de recommandation
Certains domaines reposent sur des bases vitales (conduite automatique)
## Mecanismes de l'AI et reseaux de neurones
Principe de base : on ne donne pas une definition complete de ce que l'on cherche mais l'ensemble des donnees qui permettent de determiner si les donnees correspondent

Differentes categories de prediction de l'information :
- Apprentissage supervise : On donne des donnees et les labels correspondants
- Apprentissage non-supervise : On donne seulement les donnees (test de segmentation) -> extraction de schema recurrents (pas explicable mais observable)
- Apprentissage par renforcement : Suppose que l'IA est en lien avec le monde exterieur. Les signaux qu'elle recoit de l'exterieur lui permettent de determiner la valeur de ces actions
On peut resumer le principe de base ainsi : 
(voir schema)

Deux phases : Apprentissage et Test. Durant la phase de test; on recherche a trouver la fonction qui permet de distinguer les donnees le mieux possible

Dans la phase de Test; on cherche a verifier si notre fonction valide des donnees qu'il n'a jamais vu (prediction)

### Reseaux de neurones
Fonction caracteristique; base du deep learning. 

Modelisation mathematique du neurone biologique : collecte d'informations via les dendrites et synthetisation pour renvoyer une information via l'axone (ou pas)

Reseaux a propagation directe : Couche d'entree -> Couches cachees -> Couche de sortie 

Utile pour decomposer des informations complexe dans le reseau en differents niveaux d'abstraction

Pour entrainer ces reseaux; on utilise des probas sur l'erreur de mesure en sortie (erreur quadratique) -> prinicipe de retro-propagation
## Liens entre l'AI et cybersecurite
Possible d'envisager le ML comme un outil de detection (malware; systeme) -> permet d'analyser un grand nombre de fichiers 

Possible de l'utiliser en red team -> failles; bruteforce; fuzzing... -> vient pour automatiser les attaques

**Il faut prendre en compte la vulnerabilites des systemes intelligents eux-meme (algorithmes)**

Exemple : Une modification infime peut completement changer l'interpretation du systeme (bruit) -> exemple adversaire

**Attaque par evasion** : Attaque qui consiste a sortir d'un systeme ou de modifier son comportement pour en sortir -> se base sur la faille des IID 

**Attaques par empoisonnement** : Corruption du jeu de donnees par un tier qui modifie les resultats

**Exemples adversaires** :  Minimisation du risque empirique lie a la fonction de perte du systeme (-> comment les donnes sont labelisees). On appelle exemples adversaires naturels les exemples qui trompent et le systeme et l'observateur

Entropie croisee : methode de validation des donnees pour les reseaux de neurones 

Gradient signe rapide : Utilisation d'un masque de bruit pour generer des exemples adversaires

Soumettre des donnes qui ne sont pas conformes a celles utilisees pendant l'apprentissage

**IID** : Hypothese faite sur les donnees (Independant et Identiquement Distribues)

## Attaques et defenses
**Concept de Confidentialite differentielle** : Ajout de donnees permettant d'eviter que le croisement des donnees sur plusieurs bases qui permet de retrouver des donnees (croisement entre une base Netflix anonymisee et une base IMBD permet de desanonymiser)

**Attaque par vol de modele** : Retrouver un modele a partir d'un ensemble de resultats -> approche en boite noire (pas de classifieur) -> probleme de type NP-hard (mais possible avec un certain nombre de requetes faire une Reverse-Engineering des modeles)

Defense par watermarking : ajout d'une valeur pour identifier un modele. Ne doit pas modifier les performances du modele et doit rester secret  

**Protection contre les exemples adversaires** : Plusieurs manieres : 
- Minimisation du risque robuste empirique : Utilisation des exemples adversaires pour re generer des classifieurs : **Adversarial re-training**
- Le bruit peut etre detruit/degrade si l'image est reproduite physiquement (photo)

---
##Bilan 
1. Methodes de recherches; pas d'application dans le monde commun -> domaine en pleine expansion
2. Questions applicatives : la securite des algorithmes d'apprentissage doit etre garantie vu la place du ML 
3. La comprehension de ces questions se base sur la comprehension des techniques de bases du ML
